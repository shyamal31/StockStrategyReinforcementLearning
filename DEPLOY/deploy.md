# Model Deployment with AWS SageMaker and Lambda API Endpoint

This guide provides step-by-step instructions for deploying a machine learning model on AWS SageMaker and creating a REST API endpoint using AWS Lambda and API Gateway.

## Steps for Deployment

### 1. Preparing the Deployment Folder
   - Use the `deploy` folder as it is for the deployment. This folder should include all necessary files and dependencies required by the model.

### 2. Upload Model to S3
   - Create an S3 bucket on AWS.
   - Upload the `model.tar.gz` file into this bucket.

### 3. Launch SageMaker Studio
   - Open SageMaker Studio on AWS.
   - From the left panel, navigate to **Models** and select **Deployable Models**.

### 4. Configure Model Deployment
   - Choose the default **PyTorch container** with the latest version.
   - Select appropriate hardware configurations based on your needs.
   - Enter the S3 bucket URI where the model file (`model.tar.gz`) is stored.
   - Set the required **IAM role** for accessing the S3 bucket and other resources.

### 5. Create and Configure the Endpoint
   - In SageMaker, create an endpoint using the specified configurations for deploying the model.
   - Wait until the endpoint status changes to `InService`.

### 6. Deploy the Model
   - Once the endpoint is live, proceed to test the model.

### 7. Test the Model
   - Test the deployed model with JSON input. For example:
     ```json
     {
       "ticker": "AAPL",
       "shares": 1000,
       "time_horizon": 390
     }
     ```
   - The SageMaker endpoint will return the predicted output.

### 8. Create API Endpoint with Lambda and API Gateway
   - To mimic the API endpoint call, create a Lambda function and an API endpoint using API Gateway.

### Lambda Function Code

   The following is the `lambda_handler.py` code for handling the API request and invoking the SageMaker endpoint.

   ```python
   import json
   import boto3
   sagemaker_runtime = boto3.client('sagemaker-runtime')

   def lambda_handler(event, context):
       # Extract parameters from the API request
       ticker = event.get("ticker", "AAPL")
       shares = event.get("shares", 1000)
       time_horizon = event.get("time_horizon", 390)

       # Prepare the payload for SageMaker
       payload = json.dumps({
           "ticker": ticker,
           "shares": shares,
           "time_horizon": time_horizon
       })

       # Invoke the SageMaker endpoint
       response = sagemaker_runtime.invoke_endpoint(
           EndpointName='<your_endpoint_name>',
           ContentType='application/json',
           Body=payload
       )

       # Parse the SageMaker response
       result = json.loads(response['Body'].read().decode())
       return {
           'statusCode': 200,
           'body': json.dumps(result)
       }
   ```

### 9. Testing the API Endpoint
   - After deploying the Lambda function and setting up the API Gateway, you can test the API endpoint.
   - Use the following commands or tools:

     #### a. CURL Command
     ```bash
     curl -X POST https://<api-id>.execute-api.us-east-1.amazonaws.com/prod/inference \
     -H "Content-Type: application/json" \
     -d '{"ticker": "AAPL", "shares": 1000, "time_horizon": 390}'
     ```

     #### b. Postman
     - Set the request type to `POST`.
     - Use the API URL generated by API Gateway.
     - In the body, add JSON data:
       ```json
       {
         "ticker": "AAPL",
         "shares": 1000,
         "time_horizon": 390
       }
       ```

## Important Notes

- **IAM Role**: Ensure the IAM role assigned to SageMaker and Lambda has the necessary permissions for accessing S3 and invoking the SageMaker runtime.
- **Endpoint Name**: Replace `<your_endpoint_name>` in `lambda_handler.py` with your SageMaker endpoint name.
- **Testing**: Validate each step before moving to the next to ensure smooth deployment and debugging.

## Contact
For any questions or issues, please reach out to me at [shyamalgandhi.applyusa@gmail.com](mailto:shyamalgandhi.applyusa@gmail.com)
